{
  "backend": {
    "host": "localhost",
    "port": 5000,
    "model_type": "chatgpt",
    "openai": {
      "model": "chatgpt-4o-latest"
    },
    "chunk_size": 1500,
    "max_context_chunks": 3
  },
  "frontend": {
    "host": "localhost",
    "port": 3000
  },
  "rag": {
    "code_directories": [
      "/home/roman/Desktop/ML/pipeline"
    ],
    "embeddings_cache": "./cache/embeddings.npz"
  }
} 